{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split # for splitting the data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf # keras is a sub-library of tensorflow, since tensorflow 2.0\n",
    "from tensorflow.keras.models import Sequential # for creating the architecture\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import L2\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "traindf = pd.read_csv(\"dota2Train.csv\", header = None)\n",
    "testdf = pd.read_csv(\"dota2Test.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...  107  108  109  110  \\\n",
      "0   -1  223    2    2    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    1  152    2    2    0    0    0    1    0   -1  ...    0    0    0    0   \n",
      "2    1  131    2    2    0    0    0    1    0   -1  ...    0    0    0    0   \n",
      "3    1  154    2    2    0    0    0    0    0    0  ...   -1    0    0    0   \n",
      "4   -1  171    2    3    0    0    0    0    0   -1  ...    0    0    0    0   \n",
      "\n",
      "   111  112  113  114  115  116  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 117 columns]\n",
      "0      int64\n",
      "1      int64\n",
      "2      int64\n",
      "3      int64\n",
      "4      int64\n",
      "       ...  \n",
      "112    int64\n",
      "113    int64\n",
      "114    int64\n",
      "115    int64\n",
      "116    int64\n",
      "Length: 117, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Checking the data\n",
    "print(traindf.head())\n",
    "print(traindf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    4    5    6    7    8    9    10   11   12   ...  107  108  109  110  \\\n",
       "0   -1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    1    0    0    0    1    0   -1    0    0    0  ...    0    0    0    0   \n",
       "2    1    0    0    0    1    0   -1    0    0    0  ...    0    0    0    0   \n",
       "3    1    0    0    0    0    0    0   -1    0    0  ...   -1    0    0    0   \n",
       "4   -1    0    0    0    0    0   -1    0    0   -1  ...    0    0    0    0   \n",
       "\n",
       "   111  112  113  114  115  116  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop first three columns because ID and Gamemodes\n",
    "traindf = traindf.drop(traindf.columns[[1, 2, 3]], axis=1)\n",
    "testdf = testdf.drop(testdf.columns[[1, 2, 3]], axis=1)\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    4    5    6    7    8    9    10   11   12   ...  107  108  109  110  \\\n",
       "0  0.0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1  1.0    0    0    0    1    0    0    0    0    0  ...    0    0    0    0   \n",
       "2  1.0    0    0    0    1    0    0    0    0    0  ...    0    0    0    0   \n",
       "3  1.0    0    0    0    0    0    0    0    0    0  ...    1    0    0    0   \n",
       "4  0.0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   111  112  113  114  115  116  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping the data to one hot encoding in training-data\n",
    "winnerHeroes = traindf.drop(traindf.columns[[0]], axis=1).replace(-1,0)\n",
    "looserHeroes = traindf.drop(traindf.columns[[0]], axis=1).replace(1,0) * -1\n",
    "label = (traindf.iloc[:,0]+1)/2\n",
    "\n",
    "# adding everything back together\n",
    "traindf = pd.concat([label, winnerHeroes, looserHeroes], axis=1)\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    4    5    6    7    8    9    10   11   12   ...  107  108  109  110  \\\n",
       "0  0.0    0    0    0    0    0    0    0    0    1  ...    1    0    0    0   \n",
       "1  1.0    0    0    0    0    0    0    0    0    1  ...    1    0    0    0   \n",
       "2  0.0    1    0    0    0    0    0    0    0    1  ...    0    0    0    0   \n",
       "3  1.0    0    0    0    0    0    0    0    0    1  ...    0    0    0    0   \n",
       "4  1.0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   111  112  113  114  115  116  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping the data to one hot encoding in testing-data\n",
    "winnerHeroes = testdf.drop(testdf.columns[[0]], axis=1).replace(-1,0)\n",
    "looserHeroes = testdf.drop(testdf.columns[[0]], axis=1).replace(1,0) * -1\n",
    "label = (testdf.iloc[:,0]+1)/2\n",
    "\n",
    "# adding everything back together\n",
    "testdf = pd.concat([label, winnerHeroes, looserHeroes], axis=1)\n",
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize output variable\n",
    "# traindf = traindf / 2 + 0.5\n",
    "# testdf = testdf / 2 + 0.5\n",
    "# testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing for duplicates\n",
    "traindf.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing for duplicates without result-column\n",
    "traindf.drop(traindf.columns[[0]], axis=1).duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92650, 226)\n",
      "(92650,)\n",
      "(10294, 226)\n",
      "(10294,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting in X and Y\n",
    "traindf_numpy = traindf.to_numpy()\n",
    "testdf_numpy = testdf.to_numpy()\n",
    "y_train = traindf_numpy[:,0]\n",
    "X_train = traindf_numpy[:,1:]\n",
    "testnpa_y = testdf_numpy[:,0]\n",
    "testnpa_X = testdf_numpy[:,1:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(testnpa_X.shape)\n",
    "print(testnpa_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_validation: (5147, 226)\n",
      "X_test: (5147, 226)\n",
      "y_validation: (5147,)\n",
      "y_test: (5147,)\n"
     ]
    }
   ],
   "source": [
    "splitpercentage = 0.5\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(testnpa_X, testnpa_y, test_size=splitpercentage)\n",
    "print(\"X_validation: \" + str(X_validation.shape))\n",
    "print(\"X_test: \" + str(X_test.shape))\n",
    "print(\"y_validation: \" + str(y_validation.shape))\n",
    "print(\"y_test: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 12:51:09.537851: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create big model :)\n",
    "model_big = tf.keras.models.Sequential()\n",
    "input_shape = (226,)\n",
    "model_big.add(Dense(300, input_shape=input_shape, activation=\"relu\"))\n",
    "model_big.add(Dense(200, activation=\"relu\"))\n",
    "model_big.add(Dense(100, activation=\"relu\"))\n",
    "model_big.add(Dense(50, activation=\"relu\"))\n",
    "model_big.add(Dense(25, activation=\"relu\"))\n",
    "model_big.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               68100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,751\n",
      "Trainable params: 154,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_big.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_big.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6911 - accuracy: 0.5271 - val_loss: 0.6892 - val_accuracy: 0.5364\n",
      "Epoch 2/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6883 - accuracy: 0.5395 - val_loss: 0.6861 - val_accuracy: 0.5527\n",
      "Epoch 3/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6827 - accuracy: 0.5600 - val_loss: 0.6802 - val_accuracy: 0.5640\n",
      "Epoch 4/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6749 - accuracy: 0.5775 - val_loss: 0.6755 - val_accuracy: 0.5733\n",
      "Epoch 5/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6687 - accuracy: 0.5882 - val_loss: 0.6722 - val_accuracy: 0.5850\n",
      "Epoch 6/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6648 - accuracy: 0.5956 - val_loss: 0.6707 - val_accuracy: 0.5819\n",
      "Epoch 7/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6619 - accuracy: 0.6022 - val_loss: 0.6701 - val_accuracy: 0.5831\n",
      "Epoch 8/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6598 - accuracy: 0.6048 - val_loss: 0.6701 - val_accuracy: 0.5838\n",
      "Epoch 9/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6579 - accuracy: 0.6085 - val_loss: 0.6701 - val_accuracy: 0.5854\n",
      "Epoch 10/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6561 - accuracy: 0.6106 - val_loss: 0.6688 - val_accuracy: 0.5846\n",
      "Epoch 11/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6542 - accuracy: 0.6136 - val_loss: 0.6696 - val_accuracy: 0.5887\n",
      "Epoch 12/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6522 - accuracy: 0.6171 - val_loss: 0.6701 - val_accuracy: 0.5842\n",
      "Epoch 13/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6502 - accuracy: 0.6196 - val_loss: 0.6700 - val_accuracy: 0.5848\n",
      "Epoch 14/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6480 - accuracy: 0.6230 - val_loss: 0.6711 - val_accuracy: 0.5854\n",
      "Epoch 15/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6454 - accuracy: 0.6268 - val_loss: 0.6706 - val_accuracy: 0.5871\n",
      "Epoch 16/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6426 - accuracy: 0.6313 - val_loss: 0.6752 - val_accuracy: 0.5833\n",
      "Epoch 17/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6397 - accuracy: 0.6343 - val_loss: 0.6746 - val_accuracy: 0.5854\n",
      "Epoch 18/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6357 - accuracy: 0.6381 - val_loss: 0.6793 - val_accuracy: 0.5821\n",
      "Epoch 19/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6320 - accuracy: 0.6445 - val_loss: 0.6806 - val_accuracy: 0.5788\n",
      "Epoch 20/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6272 - accuracy: 0.6504 - val_loss: 0.6851 - val_accuracy: 0.5778\n",
      "Epoch 21/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6222 - accuracy: 0.6555 - val_loss: 0.6873 - val_accuracy: 0.5803\n",
      "Epoch 22/25\n",
      "1448/1448 [==============================] - 4s 2ms/step - loss: 0.6165 - accuracy: 0.6612 - val_loss: 0.6969 - val_accuracy: 0.5733\n",
      "Epoch 23/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6100 - accuracy: 0.6689 - val_loss: 0.6966 - val_accuracy: 0.5708\n",
      "Epoch 24/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6034 - accuracy: 0.6748 - val_loss: 0.7056 - val_accuracy: 0.5671\n",
      "Epoch 25/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.5953 - accuracy: 0.6837 - val_loss: 0.7119 - val_accuracy: 0.5695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca57831160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_big.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 300)               68100     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 25)                1275      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 25)                0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,751\n",
      "Trainable params: 154,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create big dropout model :)\n",
    "model_big_drop = tf.keras.models.Sequential()\n",
    "input_shape = (226,)\n",
    "model_big_drop.add(Dense(300, input_shape=input_shape, activation=\"relu\"))\n",
    "model_big_drop.add(Dropout(0.2))\n",
    "model_big_drop.add(Dense(200, activation=\"relu\"))\n",
    "model_big_drop.add(Dropout(0.2))\n",
    "model_big_drop.add(Dense(100, activation=\"relu\"))\n",
    "model_big_drop.add(Dropout(0.2))\n",
    "model_big_drop.add(Dense(50, activation=\"relu\"))\n",
    "model_big_drop.add(Dropout(0.2))\n",
    "model_big_drop.add(Dense(25, activation=\"relu\"))\n",
    "model_big_drop.add(Dropout(0.2))\n",
    "model_big_drop.add(Dense(1, activation=\"sigmoid\"))\n",
    "model_big_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_big_drop.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_big_drop.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6919 - accuracy: 0.5230 - val_loss: 0.6910 - val_accuracy: 0.5292\n",
      "Epoch 2/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6913 - accuracy: 0.5264 - val_loss: 0.6905 - val_accuracy: 0.5312\n",
      "Epoch 3/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6910 - accuracy: 0.5251 - val_loss: 0.6897 - val_accuracy: 0.5300\n",
      "Epoch 4/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6900 - accuracy: 0.5304 - val_loss: 0.6881 - val_accuracy: 0.5430\n",
      "Epoch 5/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6885 - accuracy: 0.5378 - val_loss: 0.6853 - val_accuracy: 0.5537\n",
      "Epoch 6/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6866 - accuracy: 0.5450 - val_loss: 0.6824 - val_accuracy: 0.5663\n",
      "Epoch 7/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6848 - accuracy: 0.5539 - val_loss: 0.6795 - val_accuracy: 0.5712\n",
      "Epoch 8/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6818 - accuracy: 0.5633 - val_loss: 0.6773 - val_accuracy: 0.5741\n",
      "Epoch 9/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6795 - accuracy: 0.5695 - val_loss: 0.6756 - val_accuracy: 0.5768\n",
      "Epoch 10/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6778 - accuracy: 0.5733 - val_loss: 0.6742 - val_accuracy: 0.5761\n",
      "Epoch 11/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6759 - accuracy: 0.5780 - val_loss: 0.6737 - val_accuracy: 0.5796\n",
      "Epoch 12/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6749 - accuracy: 0.5805 - val_loss: 0.6725 - val_accuracy: 0.5801\n",
      "Epoch 13/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6730 - accuracy: 0.5855 - val_loss: 0.6720 - val_accuracy: 0.5807\n",
      "Epoch 14/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6715 - accuracy: 0.5876 - val_loss: 0.6714 - val_accuracy: 0.5798\n",
      "Epoch 15/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6709 - accuracy: 0.5892 - val_loss: 0.6708 - val_accuracy: 0.5827\n",
      "Epoch 16/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6694 - accuracy: 0.5915 - val_loss: 0.6705 - val_accuracy: 0.5817\n",
      "Epoch 17/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6691 - accuracy: 0.5938 - val_loss: 0.6703 - val_accuracy: 0.5798\n",
      "Epoch 18/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6683 - accuracy: 0.5929 - val_loss: 0.6702 - val_accuracy: 0.5805\n",
      "Epoch 19/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6678 - accuracy: 0.5961 - val_loss: 0.6698 - val_accuracy: 0.5801\n",
      "Epoch 20/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6669 - accuracy: 0.5969 - val_loss: 0.6701 - val_accuracy: 0.5801\n",
      "Epoch 21/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6661 - accuracy: 0.5978 - val_loss: 0.6693 - val_accuracy: 0.5825\n",
      "Epoch 22/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6663 - accuracy: 0.5975 - val_loss: 0.6691 - val_accuracy: 0.5813\n",
      "Epoch 23/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6651 - accuracy: 0.6013 - val_loss: 0.6689 - val_accuracy: 0.5838\n",
      "Epoch 24/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6649 - accuracy: 0.6012 - val_loss: 0.6686 - val_accuracy: 0.5831\n",
      "Epoch 25/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6646 - accuracy: 0.5990 - val_loss: 0.6689 - val_accuracy: 0.5815\n",
      "Epoch 26/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6640 - accuracy: 0.6016 - val_loss: 0.6686 - val_accuracy: 0.5815\n",
      "Epoch 27/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6635 - accuracy: 0.6016 - val_loss: 0.6685 - val_accuracy: 0.5834\n",
      "Epoch 28/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6628 - accuracy: 0.6037 - val_loss: 0.6683 - val_accuracy: 0.5838\n",
      "Epoch 29/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6623 - accuracy: 0.6038 - val_loss: 0.6683 - val_accuracy: 0.5823\n",
      "Epoch 30/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6618 - accuracy: 0.6039 - val_loss: 0.6686 - val_accuracy: 0.5803\n",
      "Epoch 31/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6616 - accuracy: 0.6056 - val_loss: 0.6686 - val_accuracy: 0.5815\n",
      "Epoch 32/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6612 - accuracy: 0.6071 - val_loss: 0.6683 - val_accuracy: 0.5825\n",
      "Epoch 33/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6613 - accuracy: 0.6050 - val_loss: 0.6681 - val_accuracy: 0.5840\n",
      "Epoch 34/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6606 - accuracy: 0.6071 - val_loss: 0.6678 - val_accuracy: 0.5819\n",
      "Epoch 35/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6597 - accuracy: 0.6077 - val_loss: 0.6683 - val_accuracy: 0.5796\n",
      "Epoch 36/50\n",
      "1448/1448 [==============================] - 5s 4ms/step - loss: 0.6595 - accuracy: 0.6090 - val_loss: 0.6680 - val_accuracy: 0.5825\n",
      "Epoch 37/50\n",
      "1448/1448 [==============================] - 7s 5ms/step - loss: 0.6593 - accuracy: 0.6097 - val_loss: 0.6683 - val_accuracy: 0.5813\n",
      "Epoch 38/50\n",
      "1448/1448 [==============================] - 5s 4ms/step - loss: 0.6588 - accuracy: 0.6101 - val_loss: 0.6680 - val_accuracy: 0.5813\n",
      "Epoch 39/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6576 - accuracy: 0.6116 - val_loss: 0.6679 - val_accuracy: 0.5813\n",
      "Epoch 40/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6584 - accuracy: 0.6113 - val_loss: 0.6676 - val_accuracy: 0.5819\n",
      "Epoch 41/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6578 - accuracy: 0.6128 - val_loss: 0.6677 - val_accuracy: 0.5811\n",
      "Epoch 42/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6573 - accuracy: 0.6132 - val_loss: 0.6673 - val_accuracy: 0.5838\n",
      "Epoch 43/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6568 - accuracy: 0.6147 - val_loss: 0.6676 - val_accuracy: 0.5838\n",
      "Epoch 44/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6562 - accuracy: 0.6133 - val_loss: 0.6677 - val_accuracy: 0.5831\n",
      "Epoch 45/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6555 - accuracy: 0.6143 - val_loss: 0.6679 - val_accuracy: 0.5842\n",
      "Epoch 46/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6543 - accuracy: 0.6169 - val_loss: 0.6678 - val_accuracy: 0.5813\n",
      "Epoch 47/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6540 - accuracy: 0.6170 - val_loss: 0.6676 - val_accuracy: 0.5823\n",
      "Epoch 48/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6542 - accuracy: 0.6184 - val_loss: 0.6678 - val_accuracy: 0.5834\n",
      "Epoch 49/50\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6536 - accuracy: 0.6182 - val_loss: 0.6677 - val_accuracy: 0.5825\n",
      "Epoch 50/50\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.6523 - accuracy: 0.6217 - val_loss: 0.6685 - val_accuracy: 0.5844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca2a02ff10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try with different gradient descent params\n",
    "sgd = SGD(learning_rate=0.01, momentum=0)\n",
    "model_big_drop.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_big_drop.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1448/1448 [==============================] - 6s 4ms/step - loss: 10.9132 - accuracy: 0.5162 - val_loss: 8.2324 - val_accuracy: 0.5290\n",
      "Epoch 2/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 6.4171 - accuracy: 0.5265 - val_loss: 4.9167 - val_accuracy: 0.5290\n",
      "Epoch 3/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 3.8998 - accuracy: 0.5265 - val_loss: 3.0590 - val_accuracy: 0.5290\n",
      "Epoch 4/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 2.4893 - accuracy: 0.5265 - val_loss: 2.0180 - val_accuracy: 0.5290\n",
      "Epoch 5/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 1.6990 - accuracy: 0.5265 - val_loss: 1.4349 - val_accuracy: 0.5290\n",
      "Epoch 6/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 1.2561 - accuracy: 0.5265 - val_loss: 1.1080 - val_accuracy: 0.5290\n",
      "Epoch 7/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 1.0080 - accuracy: 0.5265 - val_loss: 0.9249 - val_accuracy: 0.5290\n",
      "Epoch 8/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.8690 - accuracy: 0.5265 - val_loss: 0.8222 - val_accuracy: 0.5290\n",
      "Epoch 9/25\n",
      "1448/1448 [==============================] - 5s 3ms/step - loss: 0.7910 - accuracy: 0.5265 - val_loss: 0.7647 - val_accuracy: 0.5290\n",
      "Epoch 10/25\n",
      "1448/1448 [==============================] - 5s 4ms/step - loss: 0.7474 - accuracy: 0.5265 - val_loss: 0.7325 - val_accuracy: 0.5290\n",
      "Epoch 11/25\n",
      " 922/1448 [==================>...........] - ETA: 1s - loss: 0.7262 - accuracy: 0.5261"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [44], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model_big_drop_reg\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     15\u001b[0m model_big_drop_reg\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m model_big_drop_reg\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_validation,y_validation))\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Fachhochschule/2022:23/AI/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create big dropout model with regularization :)\n",
    "model_big_drop_reg = tf.keras.models.Sequential()\n",
    "input_shape = (226,)\n",
    "model_big_drop_reg.add(Dense(300, input_shape=input_shape, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=L2(0.01)))\n",
    "model_big_drop_reg.add(Dropout(0.2))\n",
    "model_big_drop_reg.add(Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=L2(0.01)))\n",
    "model_big_drop_reg.add(Dropout(0.2))\n",
    "model_big_drop_reg.add(Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=L2(0.01)))\n",
    "model_big_drop_reg.add(Dropout(0.2))\n",
    "model_big_drop_reg.add(Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=L2(0.01)))\n",
    "model_big_drop_reg.add(Dropout(0.2))\n",
    "model_big_drop_reg.add(Dense(25, activation=\"relu\", kernel_initializer=\"he_normal\", kernel_regularizer=L2(0.01)))\n",
    "model_big_drop_reg.add(Dropout(0.2))\n",
    "model_big_drop_reg.add(Dense(1, activation=\"sigmoid\"))\n",
    "model_big_drop_reg.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model_big_drop_reg.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create min model :)\n",
    "model_small = tf.keras.models.Sequential()\n",
    "input_shape = (226,)\n",
    "model_small.add(Dense(200, input_shape=input_shape, activation=\"relu\"))\n",
    "model_small.add(Dense(100, activation=\"relu\"))\n",
    "model_small.add(Dense(50, activation=\"relu\"))\n",
    "model_small.add(Dense(1, activation=\"sigmoid\"))\n",
    "model_small.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6909 - val_accuracy: 0.5302\n",
      "Epoch 2/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6901 - accuracy: 0.5324 - val_loss: 0.6892 - val_accuracy: 0.5331\n",
      "Epoch 3/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6879 - accuracy: 0.5414 - val_loss: 0.6868 - val_accuracy: 0.5502\n",
      "Epoch 4/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6848 - accuracy: 0.5552 - val_loss: 0.6832 - val_accuracy: 0.5627\n",
      "Epoch 5/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6803 - accuracy: 0.5664 - val_loss: 0.6788 - val_accuracy: 0.5726\n",
      "Epoch 6/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6752 - accuracy: 0.5771 - val_loss: 0.6749 - val_accuracy: 0.5813\n",
      "Epoch 7/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6707 - accuracy: 0.5853 - val_loss: 0.6721 - val_accuracy: 0.5817\n",
      "Epoch 8/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6671 - accuracy: 0.5920 - val_loss: 0.6705 - val_accuracy: 0.5862\n",
      "Epoch 9/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6646 - accuracy: 0.5964 - val_loss: 0.6697 - val_accuracy: 0.5862\n",
      "Epoch 10/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6626 - accuracy: 0.5995 - val_loss: 0.6689 - val_accuracy: 0.5862\n",
      "Epoch 11/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6612 - accuracy: 0.6019 - val_loss: 0.6684 - val_accuracy: 0.5846\n",
      "Epoch 12/25\n",
      "1448/1448 [==============================] - 4s 3ms/step - loss: 0.6598 - accuracy: 0.6048 - val_loss: 0.6685 - val_accuracy: 0.5848\n",
      "Epoch 13/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6587 - accuracy: 0.6062 - val_loss: 0.6694 - val_accuracy: 0.5842\n",
      "Epoch 14/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6577 - accuracy: 0.6084 - val_loss: 0.6688 - val_accuracy: 0.5825\n",
      "Epoch 15/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6566 - accuracy: 0.6089 - val_loss: 0.6701 - val_accuracy: 0.5838\n",
      "Epoch 16/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6556 - accuracy: 0.6105 - val_loss: 0.6684 - val_accuracy: 0.5817\n",
      "Epoch 17/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6547 - accuracy: 0.6128 - val_loss: 0.6686 - val_accuracy: 0.5842\n",
      "Epoch 18/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6537 - accuracy: 0.6130 - val_loss: 0.6686 - val_accuracy: 0.5856\n",
      "Epoch 19/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6527 - accuracy: 0.6150 - val_loss: 0.6688 - val_accuracy: 0.5850\n",
      "Epoch 20/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6517 - accuracy: 0.6170 - val_loss: 0.6690 - val_accuracy: 0.5862\n",
      "Epoch 21/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6507 - accuracy: 0.6180 - val_loss: 0.6697 - val_accuracy: 0.5817\n",
      "Epoch 22/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6495 - accuracy: 0.6195 - val_loss: 0.6692 - val_accuracy: 0.5827\n",
      "Epoch 23/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6484 - accuracy: 0.6216 - val_loss: 0.6701 - val_accuracy: 0.5844\n",
      "Epoch 24/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6473 - accuracy: 0.6234 - val_loss: 0.6702 - val_accuracy: 0.5838\n",
      "Epoch 25/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6460 - accuracy: 0.6242 - val_loss: 0.6715 - val_accuracy: 0.5825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca584767f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_small.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model_small.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 226)               51302     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 227       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,529\n",
      "Trainable params: 51,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_min = tf.keras.models.Sequential()\n",
    "input_shape = (226,)\n",
    "model_min.add(Dense(226, input_shape=input_shape, activation=\"relu\"))\n",
    "model_min.add(Dense(1, activation=\"sigmoid\"))\n",
    "model_min.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6924 - accuracy: 0.5227 - val_loss: 0.6889 - val_accuracy: 0.5349\n",
      "Epoch 2/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6836 - accuracy: 0.5565 - val_loss: 0.6832 - val_accuracy: 0.5539\n",
      "Epoch 3/25\n",
      "1448/1448 [==============================] - 3s 2ms/step - loss: 0.6780 - accuracy: 0.5739 - val_loss: 0.6794 - val_accuracy: 0.5663\n",
      "Epoch 4/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6738 - accuracy: 0.5826 - val_loss: 0.6766 - val_accuracy: 0.5695\n",
      "Epoch 5/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6705 - accuracy: 0.5891 - val_loss: 0.6746 - val_accuracy: 0.5763\n",
      "Epoch 6/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6680 - accuracy: 0.5922 - val_loss: 0.6732 - val_accuracy: 0.5788\n",
      "Epoch 7/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6660 - accuracy: 0.5948 - val_loss: 0.6724 - val_accuracy: 0.5801\n",
      "Epoch 8/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6646 - accuracy: 0.5972 - val_loss: 0.6714 - val_accuracy: 0.5809\n",
      "Epoch 9/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6633 - accuracy: 0.5993 - val_loss: 0.6709 - val_accuracy: 0.5840\n",
      "Epoch 10/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6624 - accuracy: 0.6009 - val_loss: 0.6706 - val_accuracy: 0.5842\n",
      "Epoch 11/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6616 - accuracy: 0.6020 - val_loss: 0.6706 - val_accuracy: 0.5840\n",
      "Epoch 12/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6609 - accuracy: 0.6027 - val_loss: 0.6698 - val_accuracy: 0.5856\n",
      "Epoch 13/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6604 - accuracy: 0.6040 - val_loss: 0.6698 - val_accuracy: 0.5852\n",
      "Epoch 14/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6598 - accuracy: 0.6051 - val_loss: 0.6694 - val_accuracy: 0.5860\n",
      "Epoch 15/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6594 - accuracy: 0.6048 - val_loss: 0.6694 - val_accuracy: 0.5873\n",
      "Epoch 16/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6589 - accuracy: 0.6059 - val_loss: 0.6692 - val_accuracy: 0.5867\n",
      "Epoch 17/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6585 - accuracy: 0.6064 - val_loss: 0.6691 - val_accuracy: 0.5897\n",
      "Epoch 18/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6581 - accuracy: 0.6069 - val_loss: 0.6690 - val_accuracy: 0.5864\n",
      "Epoch 19/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6577 - accuracy: 0.6074 - val_loss: 0.6690 - val_accuracy: 0.5879\n",
      "Epoch 20/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6573 - accuracy: 0.6086 - val_loss: 0.6689 - val_accuracy: 0.5885\n",
      "Epoch 21/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6569 - accuracy: 0.6086 - val_loss: 0.6689 - val_accuracy: 0.5893\n",
      "Epoch 22/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6566 - accuracy: 0.6093 - val_loss: 0.6687 - val_accuracy: 0.5908\n",
      "Epoch 23/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6562 - accuracy: 0.6100 - val_loss: 0.6688 - val_accuracy: 0.5916\n",
      "Epoch 24/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6558 - accuracy: 0.6108 - val_loss: 0.6688 - val_accuracy: 0.5873\n",
      "Epoch 25/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6554 - accuracy: 0.6111 - val_loss: 0.6687 - val_accuracy: 0.5885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca4e688310>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_min.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model_min.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6956 - accuracy: 0.5207 - val_loss: 0.6909 - val_accuracy: 0.5368\n",
      "Epoch 2/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6851 - accuracy: 0.5516 - val_loss: 0.6835 - val_accuracy: 0.5549\n",
      "Epoch 3/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6789 - accuracy: 0.5691 - val_loss: 0.6787 - val_accuracy: 0.5784\n",
      "Epoch 4/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6748 - accuracy: 0.5793 - val_loss: 0.6756 - val_accuracy: 0.5813\n",
      "Epoch 5/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6720 - accuracy: 0.5858 - val_loss: 0.6733 - val_accuracy: 0.5869\n",
      "Epoch 6/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6699 - accuracy: 0.5889 - val_loss: 0.6718 - val_accuracy: 0.5893\n",
      "Epoch 7/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6683 - accuracy: 0.5923 - val_loss: 0.6706 - val_accuracy: 0.5920\n",
      "Epoch 8/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6671 - accuracy: 0.5945 - val_loss: 0.6696 - val_accuracy: 0.5926\n",
      "Epoch 9/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6662 - accuracy: 0.5959 - val_loss: 0.6690 - val_accuracy: 0.5920\n",
      "Epoch 10/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6654 - accuracy: 0.5965 - val_loss: 0.6684 - val_accuracy: 0.5916\n",
      "Epoch 11/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6648 - accuracy: 0.5977 - val_loss: 0.6680 - val_accuracy: 0.5922\n",
      "Epoch 12/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6643 - accuracy: 0.5987 - val_loss: 0.6676 - val_accuracy: 0.5935\n",
      "Epoch 13/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6638 - accuracy: 0.5986 - val_loss: 0.6674 - val_accuracy: 0.5924\n",
      "Epoch 14/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6635 - accuracy: 0.5990 - val_loss: 0.6671 - val_accuracy: 0.5926\n",
      "Epoch 15/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6632 - accuracy: 0.6004 - val_loss: 0.6670 - val_accuracy: 0.5920\n",
      "Epoch 16/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6630 - accuracy: 0.6002 - val_loss: 0.6668 - val_accuracy: 0.5922\n",
      "Epoch 17/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6627 - accuracy: 0.6008 - val_loss: 0.6668 - val_accuracy: 0.5918\n",
      "Epoch 18/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6626 - accuracy: 0.6011 - val_loss: 0.6667 - val_accuracy: 0.5920\n",
      "Epoch 19/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6624 - accuracy: 0.6015 - val_loss: 0.6666 - val_accuracy: 0.5910\n",
      "Epoch 20/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6623 - accuracy: 0.6016 - val_loss: 0.6665 - val_accuracy: 0.5934\n",
      "Epoch 21/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6621 - accuracy: 0.6017 - val_loss: 0.6665 - val_accuracy: 0.5912\n",
      "Epoch 22/25\n",
      "1448/1448 [==============================] - 2s 2ms/step - loss: 0.6620 - accuracy: 0.6019 - val_loss: 0.6664 - val_accuracy: 0.5932\n",
      "Epoch 23/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6619 - accuracy: 0.6020 - val_loss: 0.6665 - val_accuracy: 0.5928\n",
      "Epoch 24/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6618 - accuracy: 0.6025 - val_loss: 0.6664 - val_accuracy: 0.5920\n",
      "Epoch 25/25\n",
      "1448/1448 [==============================] - 2s 1ms/step - loss: 0.6618 - accuracy: 0.6018 - val_loss: 0.6664 - val_accuracy: 0.5937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca363cb730>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_empty = tf.keras.models.Sequential()\n",
    "input_shape = (226,)\n",
    "model_empty.add(Dense(1, input_shape=input_shape, activation=\"sigmoid\"))\n",
    "model_empty.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model_empty.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# model_big.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 2ms/step\n",
      "Output shape:\n",
      "(5147, 1)\n",
      "Output first 10 values:\n",
      "[[0.26482335]\n",
      " [0.6834696 ]\n",
      " [0.4229448 ]\n",
      " [0.5287266 ]\n",
      " [0.6815128 ]\n",
      " [0.2111795 ]\n",
      " [0.653171  ]\n",
      " [0.48363686]\n",
      " [0.48022336]\n",
      " [0.52530897]]\n",
      "Labels first 10 values:\n",
      "[1. 1. 0. 1. 0. 0. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "output = model_big.predict(X_test)\n",
    "print(\"Output shape:\")\n",
    "print(output.shape)\n",
    "print(\"Output first 10 values:\")\n",
    "print(output[0:10])\n",
    "print(\"Labels first 10 values:\")\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatRoundOutput = output.flatten().round()\n",
    "flatRoundOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1521  847]\n",
      " [1284 1495]]\n"
     ]
    }
   ],
   "source": [
    "confmatrix = confusion_matrix(y_test, flatRoundOutput)\n",
    "print(confmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.heatmap(confmatrix/confmatrix.sum(), annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Dota wins prediction using neural nets')\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "\n",
    "# Labels per value\n",
    "ax.xaxis.set_ticklabels(['Lost','Won'])\n",
    "ax.yaxis.set_ticklabels(['Lost','Won'])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aba3ed7012d2edd5d25dea730c06d3b7d85ae3d9d9b410c294e160e661601804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
